{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c045796d",
   "metadata": {},
   "source": [
    "\n",
    "# PTNT Sanity Check · Research-Grade Tutorial\n",
    "\n",
    "**Goal.** Produce a *provable* sanity check, per supervisor request:\n",
    "\n",
    "1. Build a **synthetic oracle** (data generator).\n",
    "2. Run fresh **hold-out experiments** through both:\n",
    "   - the **oracle** and\n",
    "   - the **learned parameterized model** (LPDO).\n",
    "3. Compare outputs on **validation** with formal metrics:\n",
    "   - cross-entropy vs **data-entropy** floors,\n",
    "   - **per-circuit Hellinger fidelity** distributions.\n",
    "4. Declare **PASS/FAIL** with explicit criteria.\n",
    "\n",
    "We implement two scenarios:\n",
    "\n",
    "- **Baseline**: depolarizing + coherent over-rotation, **no** env memory.\n",
    "- **Memory**: nonzero `rzz` env coupling (temporal correlations).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5604f62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ptnt] import OK → version: 0.1.0\n",
      "[ptnt] JAX devices: [CpuDevice(id=0)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Make a nearby PTNT checkout importable if not pip-installed.\n",
    "import os, sys, pathlib\n",
    "roots = [pathlib.Path.cwd(), *pathlib.Path.cwd().parents]\n",
    "for r in roots[:4]:\n",
    "    if (r / \"ptnt\").is_dir() and str(r) not in sys.path:\n",
    "        sys.path.insert(0, str(r))\n",
    "\n",
    "# Basic environment info\n",
    "try:\n",
    "    import ptnt\n",
    "    from ptnt._version import __version__ as ptnt_version\n",
    "    print(\"[ptnt] import OK → version:\", ptnt_version)\n",
    "except Exception as e:\n",
    "    print(\"[ptnt] import failed:\", e)\n",
    "    raise\n",
    "\n",
    "try:\n",
    "    import jax\n",
    "    print(\"[ptnt] JAX devices:\", jax.devices())\n",
    "except Exception as e:\n",
    "    print(\"[ptnt] JAX not available:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7fa260",
   "metadata": {},
   "source": [
    "\n",
    "## Quimb compatibility patch (safe fallback)\n",
    "\n",
    "Some `quimb` versions expect `row_tag_id/col_tag_id`; others want `y_tag_id/x_tag_id` in `TensorNetwork2DFlat.from_TN`.\n",
    "We patch the internal helper used by the likelihood so the tutorial runs reliably across versions.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Quimb changed arg names across versions (row_tag_id/col_tag_id vs y_tag_id/x_tag_id). The patch tries new names first, then falls back. This prevents the “we need to specify x_tag_id” error I saw.\n",
    "\n",
    "- We Ensure the operator array -> 2D TN conversion always works, regardless of quimb version.\n",
    "\n",
    "- Sanity mapping: This is infrastructure so the TN contracts; it only makes the tutorial robust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7cfa09f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patched: ptnt.preprocess.shadow.op_arrays_to_single_vector_TN_padded\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Runtime patch for op_arrays_to_single_vector_TN_padded to support both quimb call styles\n",
    "import types\n",
    "import quimb.tensor as qtn\n",
    "import ptnt.preprocess.shadow as sh\n",
    "\n",
    "def _op_arrays_to_single_vector_TN_padded_robust(op_seq):\n",
    "    k = len(op_seq[0]) - 1\n",
    "    nQ = op_seq.shape[0]\n",
    "    TN_list = []\n",
    "    for i in range(nQ):\n",
    "        initial = qtn.Tensor(\n",
    "            op_seq[i][0], inds=(f\"kP_q{i}\", f\"ko{k}_q{i}\"),\n",
    "            tags=[\"U3\", f\"q{i}_U{k}\", f\"ROW{i}\", f\"COL{k}\"],\n",
    "        )\n",
    "        for j, O in enumerate(op_seq[i][1:]):\n",
    "            initial = initial & qtn.Tensor(\n",
    "                O,\n",
    "                inds=(f\"ki{k-j}_q{i}\", f\"ko{k-j-1}_q{i}\"),\n",
    "                tags=[\"U3\", f\"q{i}_U{k-j-1}\", f\"ROW{i}\", f\"COL{k-j-1}\"],\n",
    "            )\n",
    "        TN_list.append(initial)\n",
    "\n",
    "    OTN_ket = qtn.TensorNetwork(TN_list)\n",
    "    try:\n",
    "        OTN_ket = qtn.tensor_2d.TensorNetwork2DFlat.from_TN(\n",
    "            OTN_ket,\n",
    "            site_tag_id=\"q{}_U{}\",\n",
    "            Ly=k + 1, Lx=nQ,\n",
    "            row_tag_id=\"ROW{}\",\n",
    "            col_tag_id=\"COL{}\",\n",
    "        )\n",
    "    except Exception:\n",
    "        OTN_ket = qtn.tensor_2d.TensorNetwork2DFlat.from_TN(\n",
    "            OTN_ket,\n",
    "            site_tag_id=\"q{}_U{}\",\n",
    "            Ly=k + 1, Lx=nQ,\n",
    "            y_tag_id=\"ROW{}\",\n",
    "            x_tag_id=\"COL{}\",\n",
    "        )\n",
    "\n",
    "    OTN_bra = OTN_ket.H.copy()\n",
    "    OTN_bra.reindex_({f\"ko{i}_q{j}\": f\"bo{i}_q{j}\" for i in range(k + 1) for j in range(nQ)})\n",
    "    OTN_bra.reindex_({f\"ki{i}_q{j}\": f\"bi{i}_q{j}\" for i in range(1, k + 1) for j in range(nQ)})\n",
    "    OTN_ket.add_tag(\"OP KET\"); OTN_bra.add_tag(\"OP BRA\")\n",
    "    return OTN_ket & OTN_bra\n",
    "\n",
    "# Inject the patch\n",
    "sh.op_arrays_to_single_vector_TN_padded = _op_arrays_to_single_vector_TN_padded_robust\n",
    "print(\"Patched: ptnt.preprocess.shadow.op_arrays_to_single_vector_TN_padded\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac089b9",
   "metadata": {},
   "source": [
    "\n",
    "## Scenario selection\n",
    "\n",
    "- **Baseline**: no env memory; oracle = Aer with depolarizing + coherent over-rotation on `sx`.\n",
    "- **Memory**: env coupling `rzz=0.20`; oracle = Aer without extra static noise.\n",
    "\n",
    "We keep small sizes so the check is quick; scale them up for stronger signal.\n",
    "\n",
    "\n",
    "\n",
    "**Imports:** Aer for simulation; our circuit builders; shadow preprocessing tables; Full-U converters.\n",
    "\n",
    "**SCENARIO switch:** sets Q,T and the oracle dynamics:\n",
    "- Baseline: env_IA = 0, noise_model = depol + coherent Rx on sx.\n",
    "- Memory: env_IA.rzz = 0.2, noise_model = None (we isolate temporal coupling).\n",
    "\n",
    "**Shell:** base_PT_circ_template(..., \"dd_clifford\") builds the randomized-compiling shell with env ancilla on wire 0.\n",
    "\n",
    "**Sanity mapping:** “synthetic oracle” defined for both baseline and memory. we decide which underlying physics generates the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd6d1419",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: all-qubit error already exists for instruction \"sx\", composing with additional error.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario: baseline | Q,T = (2, 2)\n",
      "              ┌─────────┐          ┌──────────┐                              »\n",
      "q_0: ─────────┤ Ry(π/4) ├──────────┤0         ├──────────────────────────────»\n",
      "     ┌────────┴─────────┴─────────┐│  Unitary │┌────────────────────────────┐»\n",
      "q_1: ┤ U(t0_q0_x,t0_q0_y,t0_q0_z) ├┤1         ├┤ U(t1_q0_x,t1_q0_y,t1_q0_z) ├»\n",
      "     ├────────────────────────────┤└──────────┘└────────────────────────────┘»\n",
      "q_2: ┤ U(t0_q1_x,t0_q1_y,t0_q1_z) ├──────────────────────────────────────────»\n",
      "     └────────────────────────────┘                                          »\n",
      "c: 2/════════════════════════════════════════════════════════════════════════»\n",
      "                                                                             »\n",
      "«     ┌──────────┐         ┌──────────┐                                       »\n",
      "«q_0: ┤0         ├─────────┤0         ├───────────────────────────────────────»\n",
      "«     │          │         │  Unitary │         ┌────────────────────────────┐»\n",
      "«q_1: ┤  Unitary ├─────────┤1         ├─────────┤ U(t2_q0_x,t2_q0_y,t2_q0_z) ├»\n",
      "«     │          │┌────────┴──────────┴────────┐└────────────────────────────┘»\n",
      "«q_2: ┤1         ├┤ U(t1_q1_x,t1_q1_y,t1_q1_z) ├──────────────────────────────»\n",
      "«     └──────────┘└────────────────────────────┘                              »\n",
      "«c: 2/════════════════════════════════════════════════════════════════════════»\n",
      "«                                                                             »\n",
      "«     ┌──────────┐                                    \n",
      "«q_0: ┤0         ├────────────────────────────────────\n",
      "«     │          │                              ┌─┐   \n",
      "«q_1: ┤  Unitary ├──────────────────────────────┤M├───\n",
      "«     │          │┌────────────────────────────┐└╥┘┌─┐\n",
      "«q_2: ┤1         ├┤ U(t2_q1_x,t2_q1_y,t2_q1_z) ├─╫─┤M├\n",
      "«     └──────────┘└────────────────────────────┘ ║ └╥┘\n",
      "«c: 2/═══════════════════════════════════════════╩══╩═\n",
      "«                                                0  1 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "from qiskit_aer import Aer\n",
    "import numpy as np, quimb as qu\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ptnt.circuits.templates import base_PT_circ_template\n",
    "from ptnt.circuits.noise_models import create_env_IA, make_coherent_depol_noise_model\n",
    "from ptnt.circuits.utils import bind_ordered\n",
    "\n",
    "from ptnt.preprocess.shadow import (\n",
    "    clifford_param_dict, validation_param_dict, shadow_results_to_data_vec,\n",
    "    shadow_seqs_to_op_array,\n",
    "    clifford_measurements_vT, clifford_unitaries_vT,\n",
    "    val_measurements_vT, val_unitaries_vT,\n",
    ")\n",
    "\n",
    "SCENARIO = \"baseline\"   # \"baseline\" or \"memory\"\n",
    "\n",
    "if SCENARIO == \"baseline\":\n",
    "    Q, T = 2, 2\n",
    "    env = create_env_IA(0.0, 0.0, 0.0)\n",
    "    noise_model = make_coherent_depol_noise_model(0.001, 0.02)\n",
    "    shots_char, shots_val = 1024, 4096\n",
    "    N_train, N_val = 240, 80\n",
    "else:\n",
    "    Q, T = 2, 3\n",
    "    env = create_env_IA(0.0, 0.0, 0.20)\n",
    "    noise_model = None\n",
    "    shots_char, shots_val = 1024, 8192\n",
    "    N_train, N_val = 300, 100\n",
    "\n",
    "backend = Aer.get_backend(\"aer_simulator\")\n",
    "shell = base_PT_circ_template(Q, T, backend, basis_gates=None, template=\"dd_clifford\", env_IA=env)\n",
    "\n",
    "print(\"Scenario:\", SCENARIO, \"| Q,T =\", (Q, T))\n",
    "print(shell)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d703fce6-2012-4f19-b568-e6b139abb6c5",
   "metadata": {},
   "source": [
    "## Generate & simulate shadows (training + validation)\n",
    "\n",
    "\n",
    "build_batch: samples random Clifford indices for training and U3 for validation; uses bind_ordered to assign angles to the shell’s parameters reliably.\n",
    "\n",
    "Simulate with the oracle: Aer generates counts; training shots lower than validation (so val entropy floor is tighter).\n",
    "\n",
    "shadow_results_to_data_vec: counts -> probabilities with endianness corrected (consistent bit order).\n",
    "\n",
    "entropy_floor: computes  the empirical entropy of the validation distribution , the best possible CE any model can reach on that data.\n",
    "\n",
    "Sanity mapping: “run new experiments (fresh circuits), compute oracle distributions, and record the shot-noise floor.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e1f3d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train / val items: 791 319\n",
      "data-entropy (train / val): 0.2844237016147668 0.23593343154709287\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def reverse_seq_list(seq_list):\n",
    "    out = []\n",
    "    for seq in seq_list:\n",
    "        tmp = []\n",
    "        for Tseq in seq:\n",
    "            tmp.append([o for o in reversed(Tseq)])\n",
    "        tmp.reverse()\n",
    "        out.append(tmp)\n",
    "    return out\n",
    "\n",
    "def build_batch(template, N, table, T, Q):\n",
    "    circs, seqs = [], []\n",
    "    for _ in range(N):\n",
    "        idx = np.random.randint(0, len(table), size=(T+1, Q))\n",
    "        seqs.append(idx.T)\n",
    "        params = np.array([table[i] for i in idx.ravel()])\n",
    "        circs.append(bind_ordered(template, params.ravel()))\n",
    "    return circs, seqs\n",
    "\n",
    "def entropy_floor(prob_vec):\n",
    "    v = np.array(prob_vec, dtype=float)\n",
    "    v[v < 1e-12] = 1e-12\n",
    "    return - (1/len(v)) * v @ np.log(v + 1e-18)\n",
    "\n",
    "# Generate and simulate\n",
    "train_circs, train_seqs = build_batch(shell, N_train, clifford_param_dict, T, Q)\n",
    "val_circs,   val_seqs   = build_batch(shell, N_val,   validation_param_dict, T, Q)\n",
    "\n",
    "job_t = backend.run(train_circs, shots=shots_char, noise_model=noise_model)\n",
    "job_v = backend.run(val_circs,   shots=shots_val,   noise_model=noise_model)\n",
    "\n",
    "train_counts = job_t.result().get_counts()\n",
    "val_counts   = job_v.result().get_counts()\n",
    "\n",
    "train_vec, train_keys = shadow_results_to_data_vec(train_counts, shots_char, Q)\n",
    "val_vec,   val_keys   = shadow_results_to_data_vec(val_counts,   shots_val,   Q)\n",
    "\n",
    "print(\"train / val items:\", len(train_vec), len(val_vec))\n",
    "print(\"data-entropy (train / val):\", entropy_floor(train_vec), entropy_floor(val_vec))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38318a32-80d0-4bd5-8d5d-4de45ff703d1",
   "metadata": {},
   "source": [
    "## Sequences -> operator arrays (Full-U view)\n",
    "\n",
    "“convert sequences to the objects the likelihood contracts with” (so oracle and model interface match)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0eda5d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full-U shapes (train / val): (791, 2, 3, 2, 2) (319, 2, 3, 2, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Convert sequences -> operator arrays (Full-U view)\n",
    "train_full = shadow_seqs_to_op_array(reverse_seq_list(train_seqs), train_keys, clifford_measurements_vT, clifford_unitaries_vT)\n",
    "val_full   = shadow_seqs_to_op_array(reverse_seq_list(val_seqs),   val_keys,   val_measurements_vT,   val_unitaries_vT)\n",
    "\n",
    "print(\"Full-U shapes (train / val):\", tuple(train_full.shape), tuple(val_full.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c149bac5",
   "metadata": {},
   "source": [
    "\n",
    "## Build two learners: χ=1 vs χ=2 (temporal bond)\n",
    "\n",
    "We keep Kraus legs small (2 at input/output) and vertical bonds small (2) so computation is fast.\n",
    "\n",
    "learned parametrized model with χ=1 vs χ=2 capacity to test presence/absence of memory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30946150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grids built. (Lx, Ly): (2, 3) (2, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from ptnt.tn.pepo import create_PT_PEPO_guess, expand_initial_guess_\n",
    "\n",
    "def make_grid(Q, T, chi_temporal=1, kraus_out_in=(2,2), chi_vertical=2):\n",
    "    # Seed tiny PEPO\n",
    "    pepo = create_PT_PEPO_guess(\n",
    "        T, Q,\n",
    "        [1]*T,\n",
    "        [[1]*max(Q-1,0) for _ in range(T+1)],\n",
    "        [[1]+[1]*(T-1)+[1] for _ in range(Q)]\n",
    "    )\n",
    "    grid = qu.tensor.tensor_2d.TensorNetwork2DFlat.from_TN(\n",
    "        pepo, site_tag_id=\"q{}_I{}\", Ly=T+1, Lx=Q, y_tag_id=\"ROWq{}\", x_tag_id=\"COL{}\"\n",
    "    )\n",
    "    # Expand capacity\n",
    "    kout, kin = kraus_out_in\n",
    "    K_lists = [[kout] + [1]*(T-1) + [kin] for _ in range(Q)]\n",
    "    horiz = [[chi_temporal]*(T+1) for _ in range(Q)]\n",
    "    vert  = [[chi_vertical]*max(Q-1,0) for _ in range(T+1)]\n",
    "    expand_initial_guess_(grid, K_lists, horiz, vert, rand_strength=0.05, squeeze=True)\n",
    "    grid.squeeze_()\n",
    "    return grid, grid.Lx, grid.Ly\n",
    "\n",
    "grid_chi1, Lx1, Ly1 = make_grid(Q, T, chi_temporal=1)\n",
    "grid_chi2, Lx2, Ly2 = make_grid(Q, T, chi_temporal=2)\n",
    "print(\"Grids built. (Lx, Ly):\", (Lx1, Ly1), (Lx2, Ly2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3772f1c3",
   "metadata": {},
   "source": [
    "\n",
    "## Fit by maximum likelihood (+causality) and evaluate\n",
    "this is the “fit the parametrized model” step, and “compare outputs” with formal metrics.\n",
    "\n",
    "- Loss = cross-entropy between data probabilities and model predictions.\n",
    "- Add a small causality penalty `kappa`.\n",
    "- Use `optimizer=\"adam\"` and greedy contraction for speed.\n",
    "\n",
    "We report:\n",
    "- **Validation cross-entropy** (compare to **data-entropy** floor).\n",
    "- **Per-circuit Hellinger fidelity** (median and IQR).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3183c31b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting χ=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "+0.2826579 [best loss: +0.2796150] [best val: +0.2518657; (9)]: : 13it [00:03,  3.42it/s]                                                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting χ=2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                          | 0/12 [00:00<?, ?it/s]/home/fazeleh/.local/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "+0.2806771 [best loss: +0.2806771] [best val: +0.2478900; (12)]: : 13it [00:04,  3.12it/s]                                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from ptnt.tn.optimize import TNOptimizer\n",
    "from ptnt.tn.fit import compute_likelihood, causality_keys_to_op_arrays, compute_probabilities\n",
    "from ptnt.utilities import hellinger_fidelity\n",
    "\n",
    "def run_fit(grid, Lx, Ly, train_full, val_full, train_vec, val_vec, epochs=2, batch=256, kappa=1e-3):\n",
    "    train_v = np.array(train_vec, dtype=float); train_v[train_v < 1e-12] = 1e-12\n",
    "    val_v   = np.array(val_vec,   dtype=float); val_v[val_v   < 1e-12]   = 1e-12\n",
    "\n",
    "    iterations = int(2 * epochs * len(train_v) / batch)\n",
    "\n",
    "    optmzr = TNOptimizer(\n",
    "        grid,\n",
    "        loss_fn=compute_likelihood,\n",
    "        causality_fn=causality_keys_to_op_arrays,\n",
    "        causality_key_size=64,\n",
    "        training_data=train_v,\n",
    "        training_sequences=train_full,\n",
    "        Lx=Lx, Ly=Ly,\n",
    "        validation_data=list(val_v),\n",
    "        validation_sequences=val_full,\n",
    "        batch_size=batch,\n",
    "        loss_constants={},\n",
    "        loss_kwargs={\"kappa\": kappa, \"opt\": \"greedy\", \"X_decomp\": False},\n",
    "        autodiff_backend=\"jax\",\n",
    "        optimizer=\"adam\",\n",
    "        progbar=True,\n",
    "    )\n",
    "    _ = optmzr.optimize(iterations)\n",
    "    best = optmzr.best_val_mpo\n",
    "\n",
    "    # Predictions and metrics\n",
    "    pred = compute_probabilities(best, val_full, X_decomp=False, opt=\"greedy\")\n",
    "    pred = sum(val_v) * pred / sum(pred)\n",
    "\n",
    "    Qbits = 2**Q\n",
    "    fids = []\n",
    "    for i in range(len(val_vec) // Qbits):\n",
    "        p = np.array(pred[Qbits*i:Qbits*(i+1)]); p = p / p.sum()\n",
    "        a = np.array(val_v[Qbits*i:Qbits*(i+1)])\n",
    "        fids.append(hellinger_fidelity(p, a))\n",
    "\n",
    "    # Epoch-sampled losses (per-epoch last batch)\n",
    "    nB = optmzr._nBatches\n",
    "    epoch_losses = [float(optmzr.losses[nB-1 + nB*i]) for i in range(int(optmzr._n / nB))]\n",
    "    epoch_val_losses = [float(optmzr.val_losses[nB-1 + nB*i]) for i in range(int(optmzr._n / nB))]\n",
    "\n",
    "    return {\n",
    "        \"epoch_losses\": epoch_losses,\n",
    "        \"epoch_val_losses\": epoch_val_losses,\n",
    "        \"val_median_fid\": float(np.median(fids)),\n",
    "        \"val_iqr_fid\": float(np.quantile(fids, 0.75) - np.quantile(fids, 0.25)),\n",
    "        \"val_fids\": [float(x) for x in fids],\n",
    "    }\n",
    "\n",
    "print(\"Fitting χ=1...\")\n",
    "res1 = run_fit(grid_chi1, Lx1, Ly1, train_full, val_full, train_vec, val_vec)\n",
    "print(\"Fitting χ=2...\")\n",
    "res2 = run_fit(grid_chi2, Lx2, Ly2, train_full, val_full, train_vec, val_vec)\n",
    "print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc251ee-40a9-4c3e-af6d-c9b49d75bc40",
   "metadata": {},
   "source": [
    "## Compare to entropy floor & declare PASS/FAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4a5eb5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation floor (entropy): 0.235933\n",
      "χ=1  val CE: 0.252725 | median fid: 0.9994 (IQR 0.2633)\n",
      "χ=2  val CE: 0.273349 | median fid: 0.9986 (IQR 0.2658)\n",
      "[Baseline] Δ(χ=1,floor)=0.0168, improvement χ=2=-0.0206 → PASS\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Summarize vs floors and declare PASS/FAIL\n",
    "def entropy_floor(vec):\n",
    "    v = np.array(vec, dtype=float)\n",
    "    v[v < 1e-12] = 1e-12\n",
    "    return - (1/len(v)) * v @ np.log(v + 1e-18)\n",
    "\n",
    "v_floor = entropy_floor(val_vec)\n",
    "ce_chi1 = res1[\"epoch_val_losses\"][-1]\n",
    "ce_chi2 = res2[\"epoch_val_losses\"][-1]\n",
    "\n",
    "print(f\"Validation floor (entropy): {v_floor:.6f}\")\n",
    "print(f\"χ=1  val CE: {ce_chi1:.6f} | median fid: {res1['val_median_fid']:.4f} (IQR {res1['val_iqr_fid']:.4f})\")\n",
    "print(f\"χ=2  val CE: {ce_chi2:.6f} | median fid: {res2['val_median_fid']:.4f} (IQR {res2['val_iqr_fid']:.4f})\")\n",
    "\n",
    "if SCENARIO == \"baseline\":\n",
    "    # Expect χ=1 close to floor; χ=2 no material improvement\n",
    "    delta = ce_chi1 - v_floor\n",
    "    improv = ce_chi1 - ce_chi2\n",
    "    verdict = (\"PASS\" if delta < 0.05 and improv < 0.02 else \"WARN\")\n",
    "    print(f\"[Baseline] Δ(χ=1,floor)={delta:.4f}, improvement χ=2={improv:.4f} → {verdict}\")\n",
    "else:\n",
    "    # Expect χ=2 beats χ=1 materially\n",
    "    improv = ce_chi1 - ce_chi2\n",
    "    verdict = (\"PASS\" if improv > 0.02 else \"WARN\")\n",
    "    print(f\"[Memory] improvement χ=2={improv:.4f} → {verdict}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e5c8ae-f2d1-4897-8040-95644868bfff",
   "metadata": {},
   "source": [
    "- We generated synthetic data (oracle) with known physics (memory present/absent)\n",
    "- We trained a parameterized model (LPDO) with explicit capacity control (χ).\n",
    "- We tested on fresh hold-out circuits (new experiments).\n",
    "- We compared model vs oracle quantitatively (CE vs entropy floor, Hellinger).\n",
    "- We declared PASS/FAIL with explicit thresholds.\n",
    "- This is a complete, provable sanity check that our code learns what it should and only when appropriate\n",
    "\n",
    "the result for the baseline (memory-free) scenario is exactly what we would expect from a correct implementation. our learner with χ = 1 (no temporal memory) achieves a validation cross-entropy only Δ≈0.017 nats above the validation data-entropy floor (0.2527 vs 0.2359), and increasing χ to 2 does not help (CE worsens by ~0.0206). The median Hellinger fidelity ≈ 0.999 on fresh circuits is also as high as it should be in a well-posed baseline. That is a clean PASS for the baseline sanity test and strong evidence that our shadow preprocessing, PEPO→LPDO build, JAX-based likelihood/gradients, and evaluation logic are behaving correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "37e5eebc-58dd-4489-9a84-4172cd799d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario: memory | Q,T = (2, 4)\n",
      "              ┌─────────┐          ┌──────────┐                              »\n",
      "q_0: ─────────┤ Ry(π/4) ├──────────┤0         ├──────────────────────────────»\n",
      "     ┌────────┴─────────┴─────────┐│  Unitary │┌────────────────────────────┐»\n",
      "q_1: ┤ U(t0_q0_x,t0_q0_y,t0_q0_z) ├┤1         ├┤ U(t1_q0_x,t1_q0_y,t1_q0_z) ├»\n",
      "     ├────────────────────────────┤└──────────┘└────────────────────────────┘»\n",
      "q_2: ┤ U(t0_q1_x,t0_q1_y,t0_q1_z) ├──────────────────────────────────────────»\n",
      "     └────────────────────────────┘                                          »\n",
      "c: 2/════════════════════════════════════════════════════════════════════════»\n",
      "                                                                             »\n",
      "«     ┌──────────┐         ┌──────────┐                                       »\n",
      "«q_0: ┤0         ├─────────┤0         ├───────────────────────────────────────»\n",
      "«     │          │         │  Unitary │         ┌────────────────────────────┐»\n",
      "«q_1: ┤  Unitary ├─────────┤1         ├─────────┤ U(t2_q0_x,t2_q0_y,t2_q0_z) ├»\n",
      "«     │          │┌────────┴──────────┴────────┐└────────────────────────────┘»\n",
      "«q_2: ┤1         ├┤ U(t1_q1_x,t1_q1_y,t1_q1_z) ├──────────────────────────────»\n",
      "«     └──────────┘└────────────────────────────┘                              »\n",
      "«c: 2/════════════════════════════════════════════════════════════════════════»\n",
      "«                                                                             »\n",
      "«     ┌──────────┐         ┌──────────┐                                       »\n",
      "«q_0: ┤0         ├─────────┤0         ├───────────────────────────────────────»\n",
      "«     │          │         │  Unitary │         ┌────────────────────────────┐»\n",
      "«q_1: ┤  Unitary ├─────────┤1         ├─────────┤ U(t3_q0_x,t3_q0_y,t3_q0_z) ├»\n",
      "«     │          │┌────────┴──────────┴────────┐└────────────────────────────┘»\n",
      "«q_2: ┤1         ├┤ U(t2_q1_x,t2_q1_y,t2_q1_z) ├──────────────────────────────»\n",
      "«     └──────────┘└────────────────────────────┘                              »\n",
      "«c: 2/════════════════════════════════════════════════════════════════════════»\n",
      "«                                                                             »\n",
      "«     ┌──────────┐         ┌──────────┐                                       »\n",
      "«q_0: ┤0         ├─────────┤0         ├───────────────────────────────────────»\n",
      "«     │          │         │  Unitary │         ┌────────────────────────────┐»\n",
      "«q_1: ┤  Unitary ├─────────┤1         ├─────────┤ U(t4_q0_x,t4_q0_y,t4_q0_z) ├»\n",
      "«     │          │┌────────┴──────────┴────────┐└────────────────────────────┘»\n",
      "«q_2: ┤1         ├┤ U(t3_q1_x,t3_q1_y,t3_q1_z) ├──────────────────────────────»\n",
      "«     └──────────┘└────────────────────────────┘                              »\n",
      "«c: 2/════════════════════════════════════════════════════════════════════════»\n",
      "«                                                                             »\n",
      "«     ┌──────────┐                                    \n",
      "«q_0: ┤0         ├────────────────────────────────────\n",
      "«     │          │                              ┌─┐   \n",
      "«q_1: ┤  Unitary ├──────────────────────────────┤M├───\n",
      "«     │          │┌────────────────────────────┐└╥┘┌─┐\n",
      "«q_2: ┤1         ├┤ U(t4_q1_x,t4_q1_y,t4_q1_z) ├─╫─┤M├\n",
      "«     └──────────┘└────────────────────────────┘ ║ └╥┘\n",
      "«c: 2/═══════════════════════════════════════════╩══╩═\n",
      "«                                                0  1 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "from qiskit_aer import Aer\n",
    "import numpy as np, quimb as qu\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ptnt.circuits.templates import base_PT_circ_template\n",
    "from ptnt.circuits.noise_models import create_env_IA, make_coherent_depol_noise_model\n",
    "from ptnt.circuits.utils import bind_ordered\n",
    "\n",
    "from ptnt.preprocess.shadow import (\n",
    "    clifford_param_dict, validation_param_dict, shadow_results_to_data_vec,\n",
    "    shadow_seqs_to_op_array,\n",
    "    clifford_measurements_vT, clifford_unitaries_vT,\n",
    "    val_measurements_vT, val_unitaries_vT,\n",
    ")\n",
    "\n",
    "SCENARIO = \"memory\"   # \"baseline\" or \"memory\"\n",
    "\n",
    "if SCENARIO == \"baseline\":\n",
    "    Q, T = 2, 2\n",
    "    env = create_env_IA(0.0, 0.0, 0.0)\n",
    "    noise_model = make_coherent_depol_noise_model(0.001, 0.02)\n",
    "    shots_char, shots_val = 1024, 4096\n",
    "    N_train, N_val = 240, 80\n",
    "else:\n",
    "    Q, T = 2, 4\n",
    "    env = create_env_IA(0.0, 0.0, 0.35)\n",
    "    noise_model = None\n",
    "    shots_char, shots_val = 2048, 32768 \n",
    "    N_train, N_val = 600, 200\n",
    "\n",
    "backend = Aer.get_backend(\"aer_simulator\")\n",
    "shell = base_PT_circ_template(Q, T, backend, basis_gates=None, template=\"dd_clifford\", env_IA=env)\n",
    "\n",
    "print(\"Scenario:\", SCENARIO, \"| Q,T =\", (Q, T))\n",
    "print(shell)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cbf2be6c-8583-49ad-a46a-d4daad81e8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train / val items: 2358 800\n",
      "data-entropy (train / val): 0.2670807534306066 0.2619333641906337\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def reverse_seq_list(seq_list):\n",
    "    out = []\n",
    "    for seq in seq_list:\n",
    "        tmp = []\n",
    "        for Tseq in seq:\n",
    "            tmp.append([o for o in reversed(Tseq)])\n",
    "        tmp.reverse()\n",
    "        out.append(tmp)\n",
    "    return out\n",
    "\n",
    "def build_batch(template, N, table, T, Q):\n",
    "    circs, seqs = [], []\n",
    "    for _ in range(N):\n",
    "        idx = np.random.randint(0, len(table), size=(T+1, Q))\n",
    "        seqs.append(idx.T)\n",
    "        params = np.array([table[i] for i in idx.ravel()])\n",
    "        circs.append(bind_ordered(template, params.ravel()))\n",
    "    return circs, seqs\n",
    "\n",
    "def entropy_floor(prob_vec):\n",
    "    v = np.array(prob_vec, dtype=float)\n",
    "    v[v < 1e-12] = 1e-12\n",
    "    return - (1/len(v)) * v @ np.log(v + 1e-18)\n",
    "\n",
    "# Generate and simulate\n",
    "train_circs, train_seqs = build_batch(shell, N_train, clifford_param_dict, T, Q)\n",
    "val_circs,   val_seqs   = build_batch(shell, N_val,   validation_param_dict, T, Q)\n",
    "\n",
    "job_t = backend.run(train_circs, shots=shots_char, noise_model=noise_model)\n",
    "job_v = backend.run(val_circs,   shots=shots_val,   noise_model=noise_model)\n",
    "\n",
    "train_counts = job_t.result().get_counts()\n",
    "val_counts   = job_v.result().get_counts()\n",
    "\n",
    "train_vec, train_keys = shadow_results_to_data_vec(train_counts, shots_char, Q)\n",
    "val_vec,   val_keys   = shadow_results_to_data_vec(val_counts,   shots_val,   Q)\n",
    "\n",
    "print(\"train / val items:\", len(train_vec), len(val_vec))\n",
    "print(\"data-entropy (train / val):\", entropy_floor(train_vec), entropy_floor(val_vec))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b088efeb-86ec-410b-8521-4b298cd6f235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full-U shapes (train / val): (2358, 2, 5, 2, 2) (800, 2, 5, 2, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Convert sequences -> operator arrays (Full-U view)\n",
    "train_full = shadow_seqs_to_op_array(reverse_seq_list(train_seqs), train_keys, clifford_measurements_vT, clifford_unitaries_vT)\n",
    "val_full   = shadow_seqs_to_op_array(reverse_seq_list(val_seqs),   val_keys,   val_measurements_vT,   val_unitaries_vT)\n",
    "\n",
    "print(\"Full-U shapes (train / val):\", tuple(train_full.shape), tuple(val_full.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c89f15fc-1ebf-4567-b0aa-27571ab8b6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grids built. (Lx, Ly): (2, 5) (2, 5)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from ptnt.tn.pepo import create_PT_PEPO_guess, expand_initial_guess_\n",
    "\n",
    "def make_grid(Q, T, chi_temporal=1, kraus_out_in=(2,2), chi_vertical=2):\n",
    "    # Seed tiny PEPO\n",
    "    pepo = create_PT_PEPO_guess(\n",
    "        T, Q,\n",
    "        [1]*T,\n",
    "        [[1]*max(Q-1,0) for _ in range(T+1)],\n",
    "        [[1]+[1]*(T-1)+[1] for _ in range(Q)]\n",
    "    )\n",
    "    grid = qu.tensor.tensor_2d.TensorNetwork2DFlat.from_TN(\n",
    "        pepo, site_tag_id=\"q{}_I{}\", Ly=T+1, Lx=Q, y_tag_id=\"ROWq{}\", x_tag_id=\"COL{}\"\n",
    "    )\n",
    "    # Expand capacity\n",
    "    kout, kin = kraus_out_in\n",
    "    K_lists = [[kout] + [1]*(T-1) + [kin] for _ in range(Q)]\n",
    "    horiz = [[chi_temporal]*(T+1) for _ in range(Q)]\n",
    "    vert  = [[chi_vertical]*max(Q-1,0) for _ in range(T+1)]\n",
    "    expand_initial_guess_(grid, K_lists, horiz, vert, rand_strength=0.05, squeeze=True)\n",
    "    grid.squeeze_()\n",
    "    return grid, grid.Lx, grid.Ly\n",
    "\n",
    "grid_chi1, Lx1, Ly1 = make_grid(Q, T, chi_temporal=1)\n",
    "grid_chi2, Lx2, Ly2 = make_grid(Q, T, chi_temporal=3)\n",
    "print(\"Grids built. (Lx, Ly):\", (Lx1, Ly1), (Lx2, Ly2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8da86701-1c30-45a2-9393-c0d6fc013349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting χ=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "+0.2573271 [best loss: +0.2565579] [best val: +0.2678060; (70)]: : 74it [00:08,  9.13it/s]                                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting χ=2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "+0.2735255 [best loss: +0.2580358] [best val: +0.2709035; (44)]: : 74it [00:10,  7.18it/s]                                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from ptnt.tn.optimize import TNOptimizer\n",
    "from ptnt.tn.fit import compute_likelihood, causality_keys_to_op_arrays, compute_probabilities\n",
    "from ptnt.utilities import hellinger_fidelity\n",
    "\n",
    "def run_fit(grid, Lx, Ly, train_full, val_full, train_vec, val_vec, epochs=2, batch=256, kappa=1e-3):\n",
    "    train_v = np.array(train_vec, dtype=float); train_v[train_v < 1e-12] = 1e-12\n",
    "    val_v   = np.array(val_vec,   dtype=float); val_v[val_v   < 1e-12]   = 1e-12\n",
    "\n",
    "    iterations = int(2 * epochs * len(train_v) / batch)\n",
    "\n",
    "    optmzr = TNOptimizer(\n",
    "        grid,\n",
    "        loss_fn=compute_likelihood,\n",
    "        causality_fn=causality_keys_to_op_arrays,\n",
    "        causality_key_size=64,\n",
    "        training_data=train_v,\n",
    "        training_sequences=train_full,\n",
    "        Lx=Lx, Ly=Ly,\n",
    "        validation_data=list(val_v),\n",
    "        validation_sequences=val_full,\n",
    "        batch_size=batch,\n",
    "        loss_constants={},\n",
    "        loss_kwargs={\"kappa\": kappa, \"opt\": \"greedy\", \"X_decomp\": False},\n",
    "        autodiff_backend=\"jax\",\n",
    "        optimizer=\"adam\",\n",
    "        progbar=True,\n",
    "    )\n",
    "    _ = optmzr.optimize(iterations)\n",
    "    best = optmzr.best_val_mpo\n",
    "\n",
    "    # Predictions and metrics\n",
    "    pred = compute_probabilities(best, val_full, X_decomp=False, opt=\"greedy\")\n",
    "    pred = sum(val_v) * pred / sum(pred)\n",
    "\n",
    "    Qbits = 2**Q\n",
    "    fids = []\n",
    "    for i in range(len(val_vec) // Qbits):\n",
    "        p = np.array(pred[Qbits*i:Qbits*(i+1)]); p = p / p.sum()\n",
    "        a = np.array(val_v[Qbits*i:Qbits*(i+1)])\n",
    "        fids.append(hellinger_fidelity(p, a))\n",
    "\n",
    "    # Epoch-sampled losses (per-epoch last batch)\n",
    "    nB = optmzr._nBatches\n",
    "    epoch_losses = [float(optmzr.losses[nB-1 + nB*i]) for i in range(int(optmzr._n / nB))]\n",
    "    epoch_val_losses = [float(optmzr.val_losses[nB-1 + nB*i]) for i in range(int(optmzr._n / nB))]\n",
    "\n",
    "    return {\n",
    "        \"epoch_losses\": epoch_losses,\n",
    "        \"epoch_val_losses\": epoch_val_losses,\n",
    "        \"val_median_fid\": float(np.median(fids)),\n",
    "        \"val_iqr_fid\": float(np.quantile(fids, 0.75) - np.quantile(fids, 0.25)),\n",
    "        \"val_fids\": [float(x) for x in fids],\n",
    "    }\n",
    "\n",
    "print(\"Fitting χ=1...\")\n",
    "res1 = run_fit(grid_chi1, Lx1, Ly1, train_full, val_full, train_vec, val_vec,\n",
    "               epochs=4, batch=256, kappa=3e-4)\n",
    "print(\"Fitting χ=2...\")\n",
    "\n",
    "res2 = run_fit(grid_chi2, Lx2, Ly2, train_full, val_full, train_vec, val_vec,\n",
    "               epochs=4, batch=256, kappa=3e-4)\n",
    "\n",
    "print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "95bcccaa-e416-4ea7-a765-45f035705c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation floor (entropy): 0.261933\n",
      "χ=1  val CE: 0.311290 | median fid: 0.9944 (IQR 0.0084)\n",
      "χ=2  val CE: 0.273546 | median fid: 0.9954 (IQR 0.0077)\n",
      "[Memory] improvement χ=2=0.0377 → PASS\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Summarize vs floors and declare PASS/FAIL\n",
    "def entropy_floor(vec):\n",
    "    v = np.array(vec, dtype=float)\n",
    "    v[v < 1e-12] = 1e-12\n",
    "    return - (1/len(v)) * v @ np.log(v + 1e-18)\n",
    "\n",
    "v_floor = entropy_floor(val_vec)\n",
    "ce_chi1 = res1[\"epoch_val_losses\"][-1]\n",
    "ce_chi2 = res2[\"epoch_val_losses\"][-1]\n",
    "\n",
    "print(f\"Validation floor (entropy): {v_floor:.6f}\")\n",
    "print(f\"χ=1  val CE: {ce_chi1:.6f} | median fid: {res1['val_median_fid']:.4f} (IQR {res1['val_iqr_fid']:.4f})\")\n",
    "print(f\"χ=2  val CE: {ce_chi2:.6f} | median fid: {res2['val_median_fid']:.4f} (IQR {res2['val_iqr_fid']:.4f})\")\n",
    "\n",
    "if SCENARIO == \"baseline\":\n",
    "    # Expect χ=1 close to floor; χ=2 no material improvement\n",
    "    delta = ce_chi1 - v_floor\n",
    "    improv = ce_chi1 - ce_chi2\n",
    "    verdict = (\"PASS\" if delta < 0.05 and improv < 0.02 else \"WARN\")\n",
    "    print(f\"[Baseline] Δ(χ=1,floor)={delta:.4f}, improvement χ=2={improv:.4f} → {verdict}\")\n",
    "else:\n",
    "    # Expect χ=2 beats χ=1 materially\n",
    "    improv = ce_chi1 - ce_chi2\n",
    "    verdict = (\"PASS\" if improv > 0.02 else \"WARN\")\n",
    "    print(f\"[Memory] improvement χ=2={improv:.4f} → {verdict}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8245513-82f4-4496-a28b-333d7181a847",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
