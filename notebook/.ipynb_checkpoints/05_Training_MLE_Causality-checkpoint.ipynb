{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ad23783",
   "metadata": {},
   "source": [
    "# Training by Maximum Likelihood (+ Causality)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae0d025",
   "metadata": {},
   "source": [
    "\n",
    "**Goal:** run a small negative log‑likelihood fit with optional causality regularization.\n",
    "\n",
    "**Tip:** start tiny (few circuits, small bonds, 1–2 epochs), then scale.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f76b710",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Make a nearby PTNT checkout importable if not pip-installed.\n",
    "import os, sys, pathlib\n",
    "roots = [pathlib.Path.cwd(), *pathlib.Path.cwd().parents]\n",
    "for r in roots[:4]:\n",
    "    if (r / \"ptnt\").is_dir() and str(r) not in sys.path:\n",
    "        sys.path.insert(0, str(r))\n",
    "\n",
    "# Basic environment info\n",
    "try:\n",
    "    import ptnt\n",
    "    from ptnt._version import __version__ as ptnt_version\n",
    "    print(\"[ptnt] import OK → version:\", ptnt_version)\n",
    "except Exception as e:\n",
    "    print(\"[ptnt] import failed:\", e)\n",
    "    raise\n",
    "\n",
    "try:\n",
    "    import jax\n",
    "    print(\"[ptnt] JAX devices:\", jax.devices())\n",
    "except Exception as e:\n",
    "    print(\"[ptnt] JAX not available:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28feea6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Minimal pipeline: build shell → generate shadows → preprocess → build LPDO → tiny fit\n",
    "import numpy as np, quimb as qu\n",
    "from qiskit_aer import Aer\n",
    "from ptnt.circuits.templates import base_PT_circ_template\n",
    "from ptnt.circuits.noise_models import create_env_IA\n",
    "from ptnt.circuits.utils import bind_ordered\n",
    "from ptnt.preprocess.shadow import (\n",
    "    clifford_param_dict, validation_param_dict, shadow_results_to_data_vec,\n",
    "    shadow_seqs_to_op_array, pure_measurement,\n",
    "    clifford_measurements_vT, clifford_unitaries_vT\n",
    ")\n",
    "from ptnt.tn.pepo import create_PT_PEPO_guess, expand_initial_guess_\n",
    "from ptnt.tn.optimize import TNOptimizer\n",
    "from ptnt.tn.fit import compute_likelihood, causality_keys_to_op_arrays, compute_probabilities\n",
    "from ptnt.utilities import hellinger_fidelity\n",
    "\n",
    "backend = Aer.get_backend(\"aer_simulator\")\n",
    "Q, T = 2, 2\n",
    "env = create_env_IA(0.4, 0.2, 0.3)\n",
    "template = base_PT_circ_template(Q, T, backend, None, \"dd_clifford\", env)\n",
    "\n",
    "def batch(template, N, table):\n",
    "    circs, seqs = [], []\n",
    "    for _ in range(N):\n",
    "        idx = np.random.randint(0, len(table), (T+1, Q))\n",
    "        seqs.append(idx.T)\n",
    "        params = np.array([table[i] for i in idx.ravel()])\n",
    "        circs.append(bind_ordered(template, params.ravel()))\n",
    "    return circs, seqs\n",
    "\n",
    "N_train, N_val = 60, 20\n",
    "shots_char, shots_val = 256, 1024\n",
    "train_circs, train_seqs = batch(template, N_train, clifford_param_dict)\n",
    "val_circs,   val_seqs   = batch(template, N_val,   validation_param_dict)\n",
    "\n",
    "job_t = backend.run(train_circs, shots=shots_char)\n",
    "job_v = backend.run(val_circs,   shots=shots_val)\n",
    "\n",
    "train_counts = job_t.result().get_counts()\n",
    "val_counts   = job_v.result().get_counts()\n",
    "\n",
    "train_p, train_keys = shadow_results_to_data_vec(train_counts, shots_char, Q)\n",
    "val_p,   val_keys   = shadow_results_to_data_vec(val_counts,   shots_val,   Q)\n",
    "\n",
    "def reverse_seq_list(seq_list):\n",
    "    out = []\n",
    "    for seq in seq_list:\n",
    "        tmp = []\n",
    "        for Tseq in seq:\n",
    "            tmp.append([o for o in reversed(Tseq)])\n",
    "        tmp.reverse()\n",
    "        out.append(tmp)\n",
    "    return out\n",
    "\n",
    "train_full = shadow_seqs_to_op_array(reverse_seq_list(train_seqs), train_keys, clifford_measurements_vT, clifford_unitaries_vT)\n",
    "val_full   = shadow_seqs_to_op_array(reverse_seq_list(val_seqs),   val_keys,   clifford_measurements_vT, clifford_unitaries_vT)\n",
    "\n",
    "K_lists = [[2] + [1]*(T-1) + [2] for _ in range(Q)]\n",
    "vertical_bonds   = [[2 for _ in range(Q-1)]] + [[2] + [2 for _ in range(Q-3)] + [2] for _ in range(T)]\n",
    "horizontal_bonds = [1 for _ in range(T)]\n",
    "pepo = create_PT_PEPO_guess(T, Q, horizontal_bonds, vertical_bonds, K_lists)\n",
    "grid = qu.tensor.tensor_2d.TensorNetwork2DFlat.from_TN(pepo, site_tag_id=\"q{}_I{}\", Ly=T+1, Lx=Q, y_tag_id=\"ROWq{}\", x_tag_id=\"COL{}\")\n",
    "\n",
    "train_vec = np.array(train_p, dtype=float); train_vec[train_vec < 1e-12] = 1e-12\n",
    "val_vec   = np.array(val_p,   dtype=float); val_vec[val_vec   < 1e-12]   = 1e-12\n",
    "epochs, batch_size = 1, 64\n",
    "iterations = int(2 * epochs * len(train_vec) / batch_size)\n",
    "\n",
    "optmzr = TNOptimizer(\n",
    "    grid,\n",
    "    loss_fn=compute_likelihood,\n",
    "    causality_fn=causality_keys_to_op_arrays,\n",
    "    causality_key_size=32,\n",
    "    training_data=train_vec,\n",
    "    training_sequences=train_full,\n",
    "    Lx=grid.Lx, Ly=grid.Ly,\n",
    "    validation_data=list(val_vec),\n",
    "    validation_sequences=val_full,\n",
    "    batch_size=batch_size,\n",
    "    loss_constants={},\n",
    "    loss_kwargs={\"kappa\": 1e-3, \"opt\": \"greedy\", \"X_decomp\": False},\n",
    "    autodiff_backend=\"jax\",\n",
    "    optimizer={\"name\": \"adam\", \"lr\": 5e-3},\n",
    "    progbar=True,\n",
    ")\n",
    "_ = optmzr.optimize(iterations)\n",
    "best = optmzr.best_val_mpo\n",
    "\n",
    "pred = compute_probabilities(best, val_full, X_decomp=False, opt=\"greedy\")\n",
    "pred = sum(val_vec) * pred / sum(pred)\n",
    "Qbits = 2**Q\n",
    "import numpy as np\n",
    "fids = []\n",
    "for i in range(N_val):\n",
    "    p = np.array(pred[Qbits*i:Qbits*(i+1)]); p = p / p.sum()\n",
    "    a = np.array(val_vec[Qbits*i:Qbits*(i+1)])\n",
    "    fids.append(hellinger_fidelity(p, a))\n",
    "print(\"mean val fidelity (tiny demo):\", float(np.mean(fids)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}