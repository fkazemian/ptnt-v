{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbc67c95",
   "metadata": {},
   "source": [
    "\n",
    "# Figure 3 — Code‑First Tutorial (PTNT)\n",
    "\n",
    "**Goal:** teach you to reproduce and *modify* the Figure 3 experiment **purely from Python**, without YAML.\n",
    "You’ll learn how to build the circuit shell, generate shadow circuits, simulate, assemble operator arrays,\n",
    "construct the process‑tensor TN (PEPO→LPDO), and run a tiny MLE fit — with clear guidance on how to tweak numbers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52b75d1",
   "metadata": {},
   "source": [
    "\n",
    "> ### What Figure 3 shows (concept)\n",
    "> - A **baseline shell** (`dd_clifford`): at each time step, apply local 1‑qubit gates on the system, then couple each system qubit to an **environment ancilla** (qubit 0).  \n",
    "> - **Shadow data**: sample random local Cliffords per time step/qubit → bind → simulate → get bitstring histograms.  \n",
    "> - **Model**: a 2‑D **PEPO** (time × qubits) closed into an **LPDO** (local purification), guaranteeing positivity.  \n",
    "> - **Fit**: **maximum likelihood** (cross‑entropy) of the shadow histograms under the model; optionally add a **causality** penalty.  \n",
    "> - **Plots**: training/validation cross‑entropy vs. **data‑entropy** floors; optional validation **fidelity** boxplots.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae4de18",
   "metadata": {},
   "source": [
    "\n",
    "**Run notes**\n",
    "- Install PTNT in editable mode: `pip install -e .` from the repo root.  \n",
    "- CPU is fine; for GPU: ensure `nvidia-smi` works, then `pip install \"jax[cuda12]\"`.  \n",
    "- First JAX call compiles with XLA (brief warm‑up).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078da45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Make a nearby PTNT checkout importable if not pip-installed.\n",
    "import os, sys, pathlib\n",
    "roots = [pathlib.Path.cwd(), *pathlib.Path.cwd().parents]\n",
    "for r in roots[:4]:\n",
    "    if (r / \"ptnt\").is_dir() and str(r) not in sys.path:\n",
    "        sys.path.insert(0, str(r))\n",
    "\n",
    "# Imports and env info\n",
    "import importlib\n",
    "try:\n",
    "    import ptnt\n",
    "    from ptnt._version import __version__ as ptnt_version\n",
    "    print(\"[ptnt] import OK → version:\", ptnt_version)\n",
    "except Exception as e:\n",
    "    print(\"[ptnt] import failed:\", e)\n",
    "    raise\n",
    "\n",
    "try:\n",
    "    import jax\n",
    "    print(\"[ptnt] JAX devices:\", jax.devices())\n",
    "except Exception as e:\n",
    "    print(\"[ptnt] JAX not available:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a22bff",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Repository map (what file does what)\n",
    "\n",
    "- `ptnt/circuits/templates.py` — builds the **shell circuits**: `dd_clifford` (Fig. 3), `dd_rx_error` (pink/control), `dd_spillage`.\n",
    "- `ptnt/circuits/noise_models.py` — Aer backends & simple device‑style noise (depolarizing + coherent over‑rotation) and helper env‑system coupler.\n",
    "- `ptnt/circuits/utils.py` — helpers like **`bind_ordered`** (robust parameter binding) and **`sanitize_basis`**.\n",
    "- `ptnt/preprocess/shadow.py` — **Clifford/U3 tables**, endianness‑safe **counts→probs**, **operator arrays** (Full‑U & RZ views).\n",
    "- `ptnt/tn/pepo.py` — build a **PEPO** process tensor and close to **LPDO** (positive model).\n",
    "- `ptnt/tn/fit.py` — **likelihood** (and causality) computation & **probability evaluation** utilities.\n",
    "- `ptnt/tn/optimize.py` — a **stochastic optimizer** wrapper that calls your loss/grad and keeps best validation TN.\n",
    "- `ptnt/io/report.py` — writes **metrics JSON** and plots.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfc3dbd",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Build the Figure 3 shell (code‑first)\n",
    "\n",
    "We’ll build the **`dd_clifford`** template for `(Q system qubits) + 1 env ancilla` and `T time steps`.  \n",
    "We’ll also define the **environment–system** interaction `U = exp(-i H)` with XYZ couplings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bceed92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from qiskit_aer import Aer\n",
    "from ptnt.circuits.templates import base_PT_circ_template\n",
    "from ptnt.circuits.noise_models import create_env_IA\n",
    "import numpy as np\n",
    "\n",
    "# Pick your numbers here\n",
    "Q = 2          # number of system qubits (plus env=0)\n",
    "T = 2          # number of time steps\n",
    "env = create_env_IA(rxx=0.4, ryy=0.2, rzz=0.3)   # environment–system coupler\n",
    "backend = Aer.get_backend(\"aer_simulator\")\n",
    "\n",
    "# Build the shell\n",
    "circ = base_PT_circ_template(\n",
    "    n_qubits=Q, n_steps=T, backend=backend,\n",
    "    basis_gates=[\"sx\", \"rz\", \"cx\"],    # keep it simple for inspection\n",
    "    template=\"dd_clifford\", env_IA=env\n",
    ")\n",
    "print(circ)\n",
    "try:\n",
    "    display(circ.draw(output=\"mpl\"))\n",
    "except Exception:\n",
    "    print(circ.draw())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a2c41b",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Generate **shadow circuits** (random Cliffords), simulate, and get probabilities\n",
    "\n",
    "We’ll use the **Clifford table** (24 single‑qubit Cliffords) to seed random `(T+1)×Q` parameter choices per circuit,  \n",
    "bind them into the shell, simulate with Aer, and convert **counts → probabilities** with correct **endianness**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ad39ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from qiskit.circuit import Parameter\n",
    "from ptnt.preprocess.shadow import (\n",
    "    clifford_param_dict, validation_param_dict,\n",
    "    shadow_results_to_data_vec,\n",
    ")\n",
    "from ptnt.circuits.utils import bind_ordered\n",
    "\n",
    "# Small demo sizes you can scale up\n",
    "N_train = 60             # number of characterization circuits\n",
    "N_val   = 20             # number of validation circuits\n",
    "shots_char = 256\n",
    "shots_val  = 1024\n",
    "\n",
    "# Helper: build a batch of circuits from a parameter table (clifford or validation U3s)\n",
    "def build_batch(N, param_dict):\n",
    "    circs = []\n",
    "    seqs  = []\n",
    "    for _ in range(N):\n",
    "        # shape (T+1, Q) of indices into param_dict\n",
    "        idx = np.random.randint(0, len(param_dict), size=(T+1, Q))\n",
    "        seqs.append(idx.T)   # downstream expects per-qubit rows\n",
    "        # flatten corresponding (theta,phi,lambda) triples in the circuit's parameter order\n",
    "        params = np.array([param_dict[i] for i in idx.ravel()])\n",
    "        names = [p.name for p in circ.parameters]\n",
    "        vals = params.ravel()\n",
    "        bound = bind_ordered(circ, vals)\n",
    "        circs.append(bound)\n",
    "    return circs, seqs\n",
    "\n",
    "train_circs, train_seqs = build_batch(N_train, clifford_param_dict)\n",
    "val_circs,   val_seqs   = build_batch(N_val,   validation_param_dict)\n",
    "\n",
    "# Simulate\n",
    "job_train = backend.run(train_circs, shots=shots_char)\n",
    "job_val   = backend.run(val_circs,   shots=shots_val)\n",
    "\n",
    "train_counts = job_train.result().get_counts()\n",
    "val_counts   = job_val.result().get_counts()\n",
    "\n",
    "# Flatten counts → probability vector & keep per-circuit observed keys\n",
    "train_p, train_keys = shadow_results_to_data_vec(train_counts, shots=shots_char, nQ=Q)\n",
    "val_p,   val_keys   = shadow_results_to_data_vec(val_counts,   shots=shots_val,   nQ=Q)\n",
    "\n",
    "print(\"Train probs:\", len(train_p), \"Val probs:\", len(val_p))\n",
    "print(\"Example keys for circuit 0:\", train_keys[0][:4], \"...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807c6aa7",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Convert sequences → operator arrays (Full‑U and RZ views)\n",
    "\n",
    "We reverse time (contract **measure → ... → U₀**) and build batched **operator arrays** with shape  \n",
    "`(nUnique, nQ, time_slots, 2, 2)`. These are the inputs to the TN likelihood.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85028e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "from ptnt.preprocess.shadow import (\n",
    "    shadow_seqs_to_op_array, shadow_seqs_to_op_array_rz,\n",
    "    pure_measurement,\n",
    "    clifford_measurements_vT, clifford_unitaries_vT,\n",
    "    val_measurements_vT, val_unitaries_vT,\n",
    "    clifford_rz_unitaries_vT, val_rz_unitaries_vT,\n",
    ")\n",
    "\n",
    "def reverse_seq_list(seq_list):\n",
    "    out = []\n",
    "    for seq in seq_list:\n",
    "        tmp = []\n",
    "        for Tseq in seq:\n",
    "            tmp.append([o for o in reversed(Tseq)])\n",
    "        tmp.reverse()\n",
    "        out.append(tmp)\n",
    "    return out\n",
    "\n",
    "train_seqs_rev = reverse_seq_list(train_seqs)\n",
    "val_seqs_rev   = reverse_seq_list(val_seqs)\n",
    "\n",
    "train_full = shadow_seqs_to_op_array(train_seqs_rev, train_keys, clifford_measurements_vT, clifford_unitaries_vT)\n",
    "val_full   = shadow_seqs_to_op_array(val_seqs_rev,   val_keys,   val_measurements_vT,   val_unitaries_vT)\n",
    "\n",
    "train_rz = shadow_seqs_to_op_array_rz(train_seqs_rev, train_keys, pure_measurement, clifford_rz_unitaries_vT)\n",
    "val_rz   = shadow_seqs_to_op_array_rz(val_seqs_rev,   val_keys,   pure_measurement, val_rz_unitaries_vT)\n",
    "\n",
    "print(\"Full‑U arrays:\", tuple(train_full.shape), tuple(val_full.shape))\n",
    "print(\"RZ‑view arrays:\", tuple(train_rz.shape), tuple(val_rz.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bd8bf8",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Build the process tensor TN (PEPO → LPDO)\n",
    "\n",
    "We create an initial **PEPO** guess with small **Kraus**, **vertical**, and **temporal** bond dimensions, then close it into an **LPDO** (positive model).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9fb80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from ptnt.tn.pepo import create_PT_PEPO_guess, expand_initial_guess_, create_PEPO_X_decomp\n",
    "import quimb as qu\n",
    "\n",
    "# Small bonds for speed — scale these up for capacity\n",
    "K_lists = [[2] + [1]*(T-1) + [2] for _ in range(Q)]\n",
    "vertical_bonds   = [[2 for _ in range(Q-1)]] + [[2] + [2 for _ in range(Q-3)] + [2] for _ in range(T)]\n",
    "horizontal_bonds = [1 for _ in range(T)]\n",
    "\n",
    "pepo_init = create_PT_PEPO_guess(T, Q, horizontal_bonds, vertical_bonds, K_lists)\n",
    "# Optionally embed in a regular 2D grid object\n",
    "pepo_grid = qu.tensor.tensor_2d.TensorNetwork2DFlat.from_TN(pepo_init, site_tag_id=\"q{}_I{}\", Ly=T+1, Lx=Q, y_tag_id=\"ROWq{}\", x_tag_id=\"COL{}\")\n",
    "\n",
    "# Light random expansion & squeeze\n",
    "expand_initial_guess_(pepo_grid, K_lists, [[2]*(T+1) for _ in range(Q)], [[2]*(Q-1) for _ in range(T)], rand_strength=0.05, squeeze=True)\n",
    "pepo_grid.squeeze_()\n",
    "Lx, Ly = pepo_grid.Lx, pepo_grid.Ly\n",
    "\n",
    "print(\"PEPO grid Lx, Ly:\", Lx, Ly)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184226df",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Tiny MLE fit (few iterations) — see how loss moves\n",
    "\n",
    "We use the **Full‑U** view here for clarity. You can switch to the RZ‑decomp by changing the inputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5b4609",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from ptnt.tn.optimize import TNOptimizer\n",
    "from ptnt.tn.fit import compute_likelihood, causality_keys_to_op_arrays, compute_probabilities\n",
    "from ptnt.io.report import write_report\n",
    "from ptnt.utilities import hellinger_fidelity\n",
    "\n",
    "# Assemble data and sequences\n",
    "train_vec = np.array(train_p, dtype=float); train_vec[train_vec < 1e-12] = 1e-12\n",
    "val_vec   = np.array(val_p,   dtype=float); val_vec[val_vec < 1e-12]   = 1e-12\n",
    "\n",
    "data_entropy = - (1/len(train_vec)) * train_vec @ np.log(train_vec + 1e-18)\n",
    "v_data_entropy = - (1/len(val_vec)) * val_vec @ np.log(val_vec + 1e-18)\n",
    "\n",
    "# Tiny training config (fast)\n",
    "epochs = 1\n",
    "batch_size = 64\n",
    "iterations = int(2 * epochs * len(train_vec) / batch_size)\n",
    "\n",
    "optmzr = TNOptimizer(\n",
    "    pepo_grid,\n",
    "    loss_fn=compute_likelihood,\n",
    "    causality_fn=causality_keys_to_op_arrays,\n",
    "    causality_key_size=32,\n",
    "    training_data=train_vec,\n",
    "    training_sequences=train_full,\n",
    "    Lx=Lx, Ly=Ly,\n",
    "    validation_data=list(val_vec),\n",
    "    validation_sequences=val_full,\n",
    "    batch_size=batch_size,\n",
    "    loss_constants={},\n",
    "    loss_kwargs={\"kappa\": 1e-3, \"opt\": \"greedy\", \"X_decomp\": False},\n",
    "    autodiff_backend=\"jax\",\n",
    "    optimizer={\"name\": \"adam\", \"lr\": 5e-3},\n",
    "    progbar=True,\n",
    ")\n",
    "\n",
    "pepo_opt = optmzr.optimize(iterations)\n",
    "best_val_mpo = optmzr.best_val_mpo\n",
    "\n",
    "# Validation predictions → Hellinger fidelity\n",
    "v_pred = compute_probabilities(best_val_mpo, val_full, X_decomp=False, opt=\"greedy\")\n",
    "v_pred = sum(val_vec) * v_pred / sum(v_pred)\n",
    "fids = []\n",
    "for i in range(N_val):\n",
    "    tmp = v_pred[(2**Q)*i:(2**Q)*(i+1)]\n",
    "    tmp = np.array(tmp) / sum(tmp)\n",
    "    actual = np.array(val_vec[(2**Q)*i:(2**Q)*(i+1)])\n",
    "    fids.append(hellinger_fidelity(tmp, actual))\n",
    "\n",
    "print(\"Mean validation fidelity (demo):\", float(np.mean(fids)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed78de4",
   "metadata": {},
   "source": [
    "\n",
    "### Interpreting the demo\n",
    "- Loss should decrease a bit even in a tiny run — it’s a sanity check, not a full reproduction.  \n",
    "- Scale **N_train/N_val**, **shots**, **bonds**, and **epochs** upward to approach publication‑scale fidelity.  \n",
    "- You can toggle to the **RZ view** (set `X_decomp=True` and feed `*_rz` operator arrays) for the pink/control experiment path.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6811aeb3",
   "metadata": {},
   "source": [
    "\n",
    "## 7) Tweak numbers & variants\n",
    "\n",
    "- Change `Q` and `T` at the top, re‑run cells 2–6.  \n",
    "- Add device‑style noise: see `ptnt.circuits.noise_models.make_coherent_depol_noise_model`.  \n",
    "- Switch shell templates: `\"dd_rx_error\"` (shared `err_X`) or `\"dd_spillage\"` (CRX around `sx`).  \n",
    "- Try contraction optimizers: `\"greedy\"`, `\"random-greedy\"`, `\"auto-hq\"`, `\"hyper-kahypar\"` (if installed).  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}