{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4cb01a8",
   "metadata": {},
   "source": [
    "# PTNT Tutorial · Overview & Quickstart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78f2166",
   "metadata": {},
   "source": [
    "\n",
    "**Goal:** get a runnable feel for PTNT — end‑to‑end in minimal settings — and learn where each component lives.\n",
    "\n",
    "**What you'll do**\n",
    "1. Build a small circuit shell (system + environment ancilla).\n",
    "2. Generate a handful of randomized \"shadow\" circuits and simulate them.\n",
    "3. Convert sequences to **operator arrays** for the likelihood.\n",
    "4. Construct a small **process tensor** model (PEPO→LPDO).\n",
    "5. Run a tiny **maximum‑likelihood** update and inspect basic metrics.\n",
    "\n",
    "> **Run notes:** CPU is fine. For GPU, ensure `nvidia-smi` works and install `jax[cuda12]`. First JAX call will compile with XLA.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f76b710",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Make a nearby PTNT checkout importable if not pip-installed.\n",
    "import os, sys, pathlib\n",
    "roots = [pathlib.Path.cwd(), *pathlib.Path.cwd().parents]\n",
    "for r in roots[:4]:\n",
    "    if (r / \"ptnt\").is_dir() and str(r) not in sys.path:\n",
    "        sys.path.insert(0, str(r))\n",
    "\n",
    "# Basic environment info\n",
    "try:\n",
    "    import ptnt\n",
    "    from ptnt._version import __version__ as ptnt_version\n",
    "    print(\"[ptnt] import OK → version:\", ptnt_version)\n",
    "except Exception as e:\n",
    "    print(\"[ptnt] import failed:\", e)\n",
    "    raise\n",
    "\n",
    "try:\n",
    "    import jax\n",
    "    print(\"[ptnt] JAX devices:\", jax.devices())\n",
    "except Exception as e:\n",
    "    print(\"[ptnt] JAX not available:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f393300e",
   "metadata": {},
   "source": [
    "## 1) Build a small shell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd84ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from qiskit_aer import Aer\n",
    "from ptnt.circuits.templates import base_PT_circ_template\n",
    "from ptnt.circuits.noise_models import create_env_IA\n",
    "import numpy as np\n",
    "\n",
    "Q = 1   # system qubits (plus env ancilla on wire 0)\n",
    "T = 1   # time steps\n",
    "env_IA = create_env_IA(rxx=0.4, ryy=0.2, rzz=0.3)\n",
    "backend = Aer.get_backend(\"aer_simulator\")\n",
    "\n",
    "circ = base_PT_circ_template(\n",
    "    n_qubits=Q, n_steps=T, backend=backend, basis_gates=None,  # let backend choose\n",
    "    template=\"dd_clifford\", env_IA=env_IA\n",
    ")\n",
    "print(circ)\n",
    "try: display(circ.draw(output=\"mpl\"))\n",
    "except Exception: print(circ.draw())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953855b0",
   "metadata": {},
   "source": [
    "## 2) Generate and simulate tiny shadow batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f49a911",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from ptnt.circuits.utils import bind_ordered\n",
    "from ptnt.preprocess.shadow import clifford_param_dict, validation_param_dict, shadow_results_to_data_vec\n",
    "\n",
    "def build_batch(template, N, param_dict, Q, T):\n",
    "    # Build N circuits with (T+1)×Q random single-qubit choices\n",
    "    circs, seqs = [], []\n",
    "    for _ in range(N):\n",
    "        idx = np.random.randint(0, len(param_dict), size=(T+1, Q))\n",
    "        seqs.append(idx.T)\n",
    "        params = np.array([param_dict[i] for i in idx.ravel()])\n",
    "        bound = bind_ordered(template, params.ravel())\n",
    "        circs.append(bound)\n",
    "    return circs, seqs\n",
    "\n",
    "N_train, N_val = 20, 10\n",
    "shots_char, shots_val = 256, 512\n",
    "\n",
    "train_circs, train_seqs = build_batch(circ, N_train, clifford_param_dict, Q, T)\n",
    "val_circs,   val_seqs   = build_batch(circ, N_val,   validation_param_dict, Q, T)\n",
    "\n",
    "job_train = backend.run(train_circs, shots=shots_char)\n",
    "job_val   = backend.run(val_circs,   shots=shots_val)\n",
    "\n",
    "train_counts = job_train.result().get_counts()\n",
    "val_counts   = job_val.result().get_counts()\n",
    "\n",
    "train_p, train_keys = shadow_results_to_data_vec(train_counts, shots_char, Q)\n",
    "val_p,   val_keys   = shadow_results_to_data_vec(val_counts,   shots_val,   Q)\n",
    "\n",
    "print(\"train probs:\", len(train_p), \"val probs:\", len(val_p))\n",
    "print(\"example keys:\", train_keys[0][:4])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef54ca4",
   "metadata": {},
   "source": [
    "## 3) Sequences → operator arrays (Full‑U and RZ views)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d960d984",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from ptnt.preprocess.shadow import (\n",
    "    shadow_seqs_to_op_array, shadow_seqs_to_op_array_rz, pure_measurement,\n",
    "    clifford_measurements_vT, clifford_unitaries_vT,\n",
    "    val_measurements_vT, val_unitaries_vT,\n",
    "    clifford_rz_unitaries_vT, val_rz_unitaries_vT\n",
    ")\n",
    "\n",
    "def reverse_seq_list(seq_list):\n",
    "    out = []\n",
    "    for seq in seq_list:\n",
    "        tmp = []\n",
    "        for Tseq in seq:\n",
    "            tmp.append([o for o in reversed(Tseq)])\n",
    "        tmp.reverse()\n",
    "        out.append(tmp)\n",
    "    return out\n",
    "\n",
    "train_seqs_rev = reverse_seq_list(train_seqs)\n",
    "val_seqs_rev   = reverse_seq_list(val_seqs)\n",
    "\n",
    "train_full = shadow_seqs_to_op_array(train_seqs_rev, train_keys, clifford_measurements_vT, clifford_unitaries_vT)\n",
    "val_full   = shadow_seqs_to_op_array(val_seqs_rev,   val_keys,   val_measurements_vT,   val_unitaries_vT)\n",
    "\n",
    "train_rz = shadow_seqs_to_op_array_rz(train_seqs_rev, train_keys, pure_measurement, clifford_rz_unitaries_vT)\n",
    "val_rz   = shadow_seqs_to_op_array_rz(val_seqs_rev,   val_keys,   pure_measurement, val_rz_unitaries_vT)\n",
    "\n",
    "print(\"Full‑U:\", tuple(train_full.shape), tuple(val_full.shape))\n",
    "print(\"RZ‑view:\", tuple(train_rz.shape), tuple(val_rz.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e904aa1",
   "metadata": {},
   "source": [
    "## 4) Build a small process‑tensor model (PEPO → LPDO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc7166f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import quimb as qu\n",
    "from ptnt.tn.pepo import create_PT_PEPO_guess, expand_initial_guess_\n",
    "\n",
    "K_lists = [[2] + [1]*(T-1) + [2] for _ in range(Q)]\n",
    "vertical_bonds   = [[2 for _ in range(Q-1)]] + [[2] + [2 for _ in range(Q-3)] + [2] for _ in range(T)]\n",
    "horizontal_bonds = [1 for _ in range(T)]\n",
    "\n",
    "pepo = create_PT_PEPO_guess(T, Q, horizontal_bonds, vertical_bonds, K_lists)\n",
    "grid = qu.tensor.tensor_2d.TensorNetwork2DFlat.from_TN(pepo, site_tag_id=\"q{}_I{}\", Ly=T+1, Lx=Q, y_tag_id=\"ROWq{}\", x_tag_id=\"COL{}\")\n",
    "expand_initial_guess_(grid, K_lists, [[2]*(T+1) for _ in range(Q)], [[2]*(Q-1) for _ in range(T)], rand_strength=0.05, squeeze=True)\n",
    "grid.squeeze_()\n",
    "Lx, Ly = grid.Lx, grid.Ly\n",
    "print(\"grid Lx, Ly:\", Lx, Ly)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca5b289",
   "metadata": {},
   "source": [
    "## 5) Tiny maximum‑likelihood step (with causality option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da960779",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from ptnt.tn.optimize import TNOptimizer\n",
    "from ptnt.tn.fit import compute_likelihood, causality_keys_to_op_arrays, compute_probabilities\n",
    "from ptnt.utilities import hellinger_fidelity\n",
    "\n",
    "train_vec = np.array(train_p, dtype=float); train_vec[train_vec < 1e-12] = 1e-12\n",
    "val_vec   = np.array(val_p,   dtype=float); val_vec[val_vec   < 1e-12]   = 1e-12\n",
    "\n",
    "epochs, batch_size = 1, 32\n",
    "iterations = int(2 * epochs * len(train_vec) / batch_size)\n",
    "\n",
    "optmzr = TNOptimizer(\n",
    "    grid,\n",
    "    loss_fn=compute_likelihood,\n",
    "    causality_fn=causality_keys_to_op_arrays,\n",
    "    causality_key_size=16,\n",
    "    training_data=train_vec,\n",
    "    training_sequences=train_full,\n",
    "    Lx=Lx, Ly=Ly,\n",
    "    validation_data=list(val_vec),\n",
    "    validation_sequences=val_full,\n",
    "    batch_size=batch_size,\n",
    "    loss_constants={},\n",
    "    loss_kwargs={\"kappa\": 1e-3, \"opt\": \"greedy\", \"X_decomp\": False},\n",
    "    autodiff_backend=\"jax\",\n",
    "    optimizer={\"name\": \"adam\", \"lr\": 5e-3},\n",
    "    progbar=True,\n",
    ")\n",
    "_ = optmzr.optimize(iterations)\n",
    "best = optmzr.best_val_mpo\n",
    "\n",
    "# quick sanity utility: mean val fidelity on tiny split\n",
    "pred = compute_probabilities(best, val_full, X_decomp=False, opt=\"greedy\")\n",
    "pred = sum(val_vec) * pred / sum(pred)\n",
    "\n",
    "Qbits = 2**Q\n",
    "fids = []\n",
    "for i in range(N_val):\n",
    "    p = np.array(pred[Qbits*i:Qbits*(i+1)]); p = p / p.sum()\n",
    "    a = np.array(val_vec[Qbits*i:Qbits*(i+1)])\n",
    "    fids.append(hellinger_fidelity(p, a))\n",
    "print(\"mean val fidelity (tiny demo):\", float(np.mean(fids)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7930518f",
   "metadata": {},
   "source": [
    "\n",
    "**Next:** for deeper dives, open the notebooks below in order.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}